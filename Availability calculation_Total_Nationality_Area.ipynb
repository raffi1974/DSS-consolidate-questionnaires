{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8951d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set options to display all rows and columns without truncation.\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "MAIN_DATA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/arabic_questionnaires.xlsx'\n",
    "CRITERIA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/criterias.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_criteria_dict(criteria_df, key_language='arabic'):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping indicator names to their availability criteria.\n",
    "    \"\"\"\n",
    "    if key_language.lower() == 'english':\n",
    "        key_col = 'Indicator_En'\n",
    "    elif key_language.lower() == 'arabic':\n",
    "        key_col = 'Indicator_Ar'\n",
    "    else:\n",
    "        raise ValueError(\"key_language must be 'english' or 'arabic'\")\n",
    "    criteria_df.dropna(subset=[key_col], inplace=True)\n",
    "    return pd.Series(criteria_df.criteria.values, index=criteria_df[key_col]).to_dict()\n",
    "    \"\"\"\n",
    "    Calculates availability for each group, returning a collapsed Series (one result per group).\n",
    "    This function checks if data points for an indicator are present consistently across defined time windows.\n",
    "    \n",
    "    Example of the process for a single indicator group:\n",
    "    1. indicator_name = group.name[...]\n",
    "       This line just gets the name of the indicator we are working on.\n",
    "       indicator_name = \"Literacy rate\"\n",
    "\n",
    "    2. criteria = criteria_dict.get(indicator_name, 1)\n",
    "       This looks up the \"Literacy rate\" in our criteria dictionary and finds its requirement.\n",
    "       criteria = 2 (meaning we need at least 2 data points per 5-year window)\n",
    "\n",
    "    3. binned_years = pd.cut(...)\n",
    "       This is the categorization step. It takes our list of years and puts each one into a 5-year \"bucket\".\n",
    "       2011 -> [2010, 2015), 2012 -> [2010, 2015)\n",
    "       2016 -> [2015, 2020), 2018 -> [2015, 2020)\n",
    "       2021 -> [2020, 2025), 2022 -> [2020, 2025), 2023 -> [2020, 2025)\n",
    "\n",
    "    4. window_counts = binned_years.value_counts()\n",
    "       This step counts how many data points landed in each bucket.\n",
    "       [2010, 2015): 2\n",
    "       [2015, 2020): 2\n",
    "       [2020, 2025): 3\n",
    "\n",
    "    5. windows_with_sufficient_data = window_counts[window_counts >= criteria]\n",
    "       This is a filter. It keeps only buckets where the count meets our criteria (>= 2).\n",
    "       [2010, 2015): Kept (because 2 >= 2)\n",
    "       [2015, 2020): Kept (because 2 >= 2)\n",
    "       [2020, 2025): Kept (because 3 >= 2)\n",
    "\n",
    "    6. sufficient_windows_set = set(windows_with_sufficient_data.index)\n",
    "       This creates a clean, unique list of the windows that passed the filter.\n",
    "       sufficient_windows_set = { [2010, 2015), [2015, 2020), [2020, 2025) }\n",
    "\n",
    "    7. return 1 if len(...) == len(...) else 0\n",
    "       The final check compares the set of windows with sufficient data against the set of ALL possible windows in our universal time range.\n",
    "       If they match perfectly, it means the indicator is fully available (returns 1), otherwise it's not (returns 0).\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e74b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read successfully.\n",
      "Cleaning source data...\n",
      "Creating year bins with hardcoded ranges...\n",
      "Data cleaning and binning complete.\n",
      "Criteria dictionary created with 85 entries.\n"
     ]
    }
   ],
   "source": [
    "#LOAD AND CLEAN DATA ---\n",
    "\n",
    "try:\n",
    "    main_df = pd.read_excel(MAIN_DATA_FILE)\n",
    "    criteria_df = pd.read_excel(CRITERIA_FILE)\n",
    "    print(\"Files read successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading files: {e}. Make sure the paths are correct.\")\n",
    "    raise e\n",
    "\n",
    "print(\"Cleaning source data...\")\n",
    "main_df = main_df.loc[:, ~main_df.columns.str.startswith('Unnamed')]\n",
    "if 'Theme' in main_df.columns:\n",
    "    main_df.rename(columns={'Theme': 'الفصل'}, inplace=True)\n",
    "for col in main_df.select_dtypes(include=['object']).columns:\n",
    "    main_df[col] = main_df[col].str.strip()\n",
    "\n",
    "# Keep only rows with a non-null value before doing anything else\n",
    "main_df = main_df[main_df['العدد'].notna()].copy()\n",
    "\n",
    "# --- NEW BINNING LOGIC ---\n",
    "def assign_bin_hardcoded(year):\n",
    "    \"\"\"Manually assigns a year to a specific, hardcoded bin.\"\"\"\n",
    "    if 2010 <= year < 2015:\n",
    "        return '[2010-2015)'\n",
    "    elif 2015 <= year < 2020:\n",
    "        return '[2015-2020)'\n",
    "    elif 2020 <= year <= 2025:  # NOTE: Includes 2025 as requested\n",
    "        return '[2020-2025]'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "print(\"Creating year bins with hardcoded ranges...\")\n",
    "main_df['year_bins'] = main_df['السنة'].apply(assign_bin_hardcoded)\n",
    "print(\"Data cleaning and binning complete.\")\n",
    "    \n",
    "#get the criteria dictionary\n",
    "criteria_dict_ar = create_criteria_dict(criteria_df, key_language='arabic')\n",
    "print(f\"Criteria dictionary created with {len(criteria_dict_ar)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE MASTERFILE\n",
    "print(\"\\n--- Creating Detailed Masterfile ---\")\n",
    "\n",
    "# 1. Get all unique values for each of the key categorical columns from the main DataFrame.\n",
    "unique_themes = main_df['الفصل'].unique()\n",
    "unique_indicators = main_df['المؤشر'].unique()\n",
    "unique_countries = main_df['الدولة'].unique()\n",
    "\n",
    "print(f\"Found {len(unique_themes)} unique themes, {len(unique_indicators)} indicators, and {len(unique_countries)} countries.\")\n",
    "\n",
    "# 2. Create the \"blank file\" by performing a Cartesian product of the unique categories.\n",
    "# This creates a DataFrame with every possible combination of theme, indicator, and country.\n",
    "masterfile = pd.MultiIndex.from_product(\n",
    "    [unique_themes, unique_indicators, unique_countries],\n",
    "    names=['الفصل', 'المؤشر', 'الدولة']\n",
    ").to_frame(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac333ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate availability for each group\n",
    "def calculate_availability(group, criteria_dict):\n",
    "    \"\"\"\n",
    "    Calculates availability for a single indicator/country group based on two conditions.\n",
    "\n",
    "    Availability is 1 if and only if both conditions are met:\n",
    "    1. The group contains data for ALL three of the required hardcoded time bins.\n",
    "    2. The number of data points in EACH of those bins is >= the criteria from the dictionary.\n",
    "\n",
    "    Args:\n",
    "        group (pd.DataFrame): A DataFrame slice for a single indicator/country.\n",
    "        criteria_dict (dict): A dictionary mapping indicator names to their criteria value (int).\n",
    "\n",
    "    Returns:\n",
    "        int: 1 if available, 0 if not available.\n",
    "    \"\"\"\n",
    "    # Define the complete set of bins that must be present in the data.\n",
    "    required_bins = {'[2010-2015)', '[2015-2020)', '[2020-2025]'}\n",
    "\n",
    "    # Get necessary values from the input group\n",
    "    indicator_name = group['المؤشر'].iloc[0]\n",
    "    criteria = criteria_dict.get(indicator_name, 1)\n",
    "    bins_in_data = set(group['year_bins'].unique())\n",
    "\n",
    "    #Condition 1: Check if the set of bins in the data matches the required set\n",
    "    bins_are_complete = (bins_in_data == required_bins)\n",
    "\n",
    "    # Condition 2: Check if the count of data points in every bin meets the criteria\n",
    "    # We only need to check this if the first condition is even potentially met.\n",
    "    all_counts_are_sufficient = False\n",
    "    if bins_are_complete:\n",
    "        # Get the number of data points (rows) for each bin.\n",
    "        counts_per_bin = group['year_bins'].value_counts()\n",
    "        # The .all() method returns True only if every count meets the criteria.\n",
    "        all_counts_are_sufficient = (counts_per_bin >= criteria).all()\n",
    "\n",
    "    # Return 1 only if both conditions were met, otherwise return 0.\n",
    "    if bins_are_complete and all_counts_are_sufficient:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc1aa5",
   "metadata": {},
   "source": [
    "#### Calculate availability fror each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5357930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Overall Group-Level Availability total\n",
    "overall_availability_scores = main_df.groupby(['المؤشر', 'الدولة']).apply(\n",
    "    calculate_availability,\n",
    "    criteria_dict=criteria_dict_ar\n",
    ").reset_index(name='التوفر الكلي') # Total Availability\n",
    "\n",
    "\n",
    "#Merge the new scores into the Masterfile ---\n",
    "masterfile = pd.merge(\n",
    "    masterfile,\n",
    "    overall_availability_scores,\n",
    "    on=['المؤشر', 'الدولة'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#General Datapoint Availability\n",
    "# As per the plan: keep specific columns, then drop duplicates based on year.\n",
    "df_general = main_df[['المؤشر', 'الدولة', 'السنة', 'العدد', 'year_bins']].copy()\n",
    "df_general.drop_duplicates(subset=['المؤشر', 'الدولة', 'السنة'], inplace=True)\n",
    "# For these unique year-rows, the datapoint is available. The value is implicitly not null.\n",
    "df_general['توفر نقطة البيانات (كلي)'] = 1\n",
    "# Select only the key columns and the new score for merging.\n",
    "datapoint_scores_general = df_general[['المؤشر', 'الدولة', 'السنة', 'توفر نقطة البيانات (كلي)']]\n",
    "\n",
    "# Merge general scores\n",
    "masterfile = pd.merge(masterfile, datapoint_scores_general, on=['المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "\n",
    "####################################################################################\n",
    "# Nationality Availability\n",
    "# Filter for relevant nationality categories\n",
    "df_nat_filtered = main_df[main_df['المواطنة'].isin(['مواطنون', 'غير مواطنين'])]\n",
    "\n",
    "# Group by year and get the max value within the valid categories\n",
    "df_nat_agg = df_nat_filtered.groupby(['المؤشر', 'الدولة', 'السنة']).agg(\n",
    "    max_value=('العدد', 'max')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "nationality_availability_scores = df_nat_agg.groupby(['المؤشر', 'الدولة']).apply(\n",
    "    calculate_availability,\n",
    "    criteria_dict=criteria_dict_ar\n",
    ").reset_index(name='التوفر حسب المواطنية')\n",
    "\n",
    "\n",
    "#Merge the nationality availability scores\n",
    "masterfile_df = pd.merge(\n",
    "    masterfile,\n",
    "    nationality_availability_scores,\n",
    "    on=['المؤشر', 'الدولة'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#Nationality Datapoint Availability\n",
    "# Create the availability column: 1 if a max value was found, 0 otherwise\n",
    "df_nat_agg['توفر نقطة البيانات (المواطنة)'] = np.where(df_nat_agg['max_value'].notna(), 1, 0)\n",
    "# Select only the key columns and the new score for merging\n",
    "datapoint_scores_nat = df_nat_agg[['المؤشر', 'الدولة', 'السنة', 'توفر نقطة البيانات (المواطنة)']]\n",
    "\n",
    "# Merge nationality scores\n",
    "masterfile = pd.merge(masterfile, datapoint_scores_nat, on=['المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "#Area Datapoint Availability\n",
    "df_area_filtered = main_df[main_df['المنطقة'].isin(['حضر', 'ريف'])]\n",
    "df_area_agg = df_area_filtered.groupby(['المؤشر', 'الدولة', 'السنة']).agg(\n",
    "    max_value=('العدد', 'max')\n",
    ").reset_index()\n",
    "\n",
    "area_availability_scores = df_area_agg.groupby(['المؤشر', 'الدولة']).apply(\n",
    "    calculate_availability,\n",
    "    criteria_dict=criteria_dict_ar\n",
    ").reset_index(name='التوفر حسب المنطقة')\n",
    "\n",
    "\n",
    "# Merge the area availability scores\n",
    "masterfile = pd.merge(\n",
    "    masterfile_df,\n",
    "    area_availability_scores,\n",
    "    on=['المؤشر', 'الدولة'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_area_agg['توفر نقطة البيانات (المنطقة)'] = np.where(df_area_agg['max_value'].notna(), 1, 0)\n",
    "datapoint_scores_area = df_area_agg[['المؤشر', 'الدولة', 'السنة', 'توفر نقطة البيانات (المنطقة)']]\n",
    "\n",
    "# Merge area scores\n",
    "masterfile = pd.merge(masterfile, datapoint_scores_area, on=['المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "masterfile.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bf873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde09d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34feff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51690c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6d9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ff3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37de443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Availability Scores ---\n",
      "Availability scores calculated successfully.\n"
     ]
    }
   ],
   "source": [
    "# %% --- CELL 5: CALCULATE AVAILABILITY SCORES (CORRECTED LOGIC) ---\n",
    "\n",
    "print(\"\\n--- Calculating Availability Scores ---\")\n",
    "\n",
    "# The correct rule: Availability = 1 ONLY IF the indicator has data in all 3 defined time bins.\n",
    "\n",
    "# --- General Availability ---\n",
    "# Group by indicator/country and count the number of unique bins for each.\n",
    "general_bin_counts = main_df.groupby(['المؤشر', 'الدولة'])['year_bins'].nunique()\n",
    "# The final score is 1 only if the count of bins is exactly 3.\n",
    "final_general_scores = (general_bin_counts == 3).astype(int)\n",
    "\n",
    "# --- Nationality Availability ---\n",
    "df_nationality = main_df[main_df['المواطنة'].isin(['مواطنون', 'غير مواطنين'])]\n",
    "nat_bin_counts = df_nationality.groupby(['المؤشر', 'الدولة'])['year_bins'].nunique()\n",
    "# The final score is 1 only if the count of bins is exactly 3.\n",
    "final_nationality_scores = (nat_bin_counts == 3).astype(int)\n",
    "\n",
    "# --- Area Availability ---\n",
    "if 'المنطقة' in main_df.columns:\n",
    "    df_area = main_df[main_df['المنطقة'].isin(['حضر', 'ريف'])]\n",
    "    area_bin_counts = df_area.groupby(['المؤشر', 'الدولة'])['year_bins'].nunique()\n",
    "    # The final score is 1 only if the count of bins is exactly 3.\n",
    "    final_area_scores = (area_bin_counts == 3).astype(int)\n",
    "else:\n",
    "    final_area_scores = pd.Series(dtype=int)\n",
    "\n",
    "# --- Combine the results ---\n",
    "indicator_country_scores = pd.DataFrame({\n",
    "    'التوفر كلي': final_general_scores,\n",
    "    'التوفر حسب المواطنية': final_nationality_scores,\n",
    "    'التوفر حسب المنطقة': final_area_scores\n",
    "}).reset_index().fillna(0)\n",
    "\n",
    "print(\"Availability scores calculated successfully.\")\n",
    "# You can now display `indicator_country_scores.head()` in a new cell to inspect the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c38207f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76d636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566a13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca740255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd57d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faae13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64f501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53cffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f129a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating and Saving All Aggregated Reports ---\n",
      "Successfully saved 'main_availability.xlsx'\n",
      "Successfully saved 'main_availability_percentage.xlsx'\n",
      "Successfully saved 'theme_country_availability.xlsx'\n",
      "Successfully saved 'indicator_country_availability.xlsx'\n",
      "Successfully saved 'country_availability.xlsx'\n",
      "Successfully saved 'heatmap_disaggregated.xlsx'\n",
      "Successfully saved 'heatmap_total.xlsx'\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "#GENERATE AGGREGATED REPORTS\n",
    "\n",
    "print(\"\\n--- Generating and Saving All Aggregated Reports ---\")\n",
    "availability_cols = ['التوفر كلي', 'التوفر حسب المواطنية', 'التوفر حسب المنطقة']\n",
    "\n",
    "# --- File 1: main_availability.xlsx ---\n",
    "# This file shows the final 0/1 availability for each indicator/country pair.\n",
    "main_availability_agg_df = masterfile_df.groupby(['المؤشر', 'الفصل', 'الدولة']).agg({\n",
    "    'التوفر كلي': 'max',\n",
    "    'التوفر حسب المواطنية': 'max',\n",
    "    'التوفر حسب المنطقة': 'max'\n",
    "}).reset_index()\n",
    "main_availability_agg_df.to_excel('main_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'main_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 2: main_availability_percentage.xlsx ---\n",
    "# This file shows the percentage of available indicators per theme and country.\n",
    "long_availability_df = main_availability_agg_df.melt(\n",
    "    id_vars=['المؤشر', 'الفصل', 'الدولة'],\n",
    "    value_vars=availability_cols,\n",
    "    var_name='نوع التوفر',\n",
    "    value_name='متوفر'\n",
    ")\n",
    "total_indicators = main_df['المؤشر'].nunique()\n",
    "availability_sums = long_availability_df.groupby(['الفصل', 'الدولة', 'نوع التوفر'])['متوفر'].apply(\n",
    "    lambda x: (x.sum() / total_indicators) * 100 if total_indicators > 0 else 0\n",
    ").reset_index(name='نسبة التوفر')\n",
    "availability_sums = availability_sums[availability_sums['نوع التوفر'] == 'التوفر كلي']\n",
    "availability_sums.to_excel('main_availability_percentage.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'main_availability_percentage.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 3: theme_country_availability.xlsx ---\n",
    "# This file shows the number and percentage of available indicators for each theme/country.\n",
    "indicators_per_theme = main_df.groupby('الفصل')['المؤشر'].nunique().reset_index(name='total_indicators_in_theme')\n",
    "theme_country_sums = main_availability_agg_df.groupby(['الفصل', 'الدولة'])[availability_cols].sum().reset_index()\n",
    "theme_country_agg_df = pd.merge(theme_country_sums, indicators_per_theme, on='الفصل', how='left')\n",
    "for col in availability_cols:\n",
    "    theme_country_agg_df[f'{col}_نسبة'] = (theme_country_agg_df[col] / theme_country_agg_df['total_indicators_in_theme']) * 100\n",
    "theme_country_agg_df.to_excel('theme_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'theme_country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 4: indicator_country_availability.xlsx ---\n",
    "# This file shows the number and percentage of countries that have data for each indicator.\n",
    "indicator_sums = main_availability_agg_df.groupby('المؤشر')[availability_cols].sum().reset_index()\n",
    "total_countries = main_df['الدولة'].nunique()\n",
    "if total_countries > 0:\n",
    "    for col in availability_cols:\n",
    "        indicator_sums[f'{col}_نسبة'] = (indicator_sums[col] / total_countries) * 100\n",
    "indicator_sums.to_excel('indicator_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'indicator_country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 5: country_availability.xlsx ---\n",
    "# This file shows the number and percentage of available indicators for each country.\n",
    "country_sums = main_availability_agg_df.groupby('الدولة')[availability_cols].sum().reset_index()\n",
    "if total_indicators > 0:\n",
    "    for col in availability_cols:\n",
    "        country_sums[f'{col}_نسبة'] = (country_sums[col] / total_indicators) * 100\n",
    "country_sums['التوفر السابق'] = ''\n",
    "country_sums.to_excel('country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 6 & 7: Heatmap Files ---\n",
    "# Disaggregated Heatmap\n",
    "heatmap_df_disaggregated = masterfile_df.groupby(\n",
    "    ['المؤشر', 'الدولة', 'السنة', 'المواطنة', 'المنطقة', 'الفصل']\n",
    ").agg({'التوفر كلي': 'max'}).reset_index()\n",
    "heatmap_df_disaggregated.to_excel('heatmap_disaggregated.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'heatmap_disaggregated.xlsx'\")\n",
    "\n",
    "# Total (Aggregated) Heatmap\n",
    "heatmap_df_total = masterfile_df.groupby(\n",
    "    ['المؤشر', 'الدولة', 'السنة', 'الفصل']\n",
    ").agg({'التوفر كلي': 'max'}).reset_index()\n",
    "heatmap_df_total.to_excel('heatmap_total.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'heatmap_total.xlsx'\")\n",
    "\n",
    "print(\"\\nAnalysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62e766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a67ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d18d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f02bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc37e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8f768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0377c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d4300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba7e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cd15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f040e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fa976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a083d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
