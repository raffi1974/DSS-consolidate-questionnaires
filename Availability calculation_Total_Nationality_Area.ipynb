{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8951d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MAIN_DATA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/arabic_questionnaires.xlsx'\n",
    "CRITERIA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/criterias.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ee798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_criteria_dict(criteria_df, key_language='arabic'):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping indicator names to their availability criteria.\n",
    "    \"\"\"\n",
    "    if key_language.lower() == 'english':\n",
    "        key_col = 'Indicator_En'\n",
    "    elif key_language.lower() == 'arabic':\n",
    "        key_col = 'Indicator_Ar'\n",
    "    else:\n",
    "        raise ValueError(\"key_language must be 'english' or 'arabic'\")\n",
    "    criteria_df.dropna(subset=[key_col], inplace=True)\n",
    "    return pd.Series(criteria_df.criteria.values, index=criteria_df[key_col]).to_dict()\n",
    "    \"\"\"\n",
    "    Calculates availability for each group, returning a collapsed Series (one result per group).\n",
    "    This function checks if data points for an indicator are present consistently across defined time windows.\n",
    "    \n",
    "    Example of the process for a single indicator group:\n",
    "    1. indicator_name = group.name[...]\n",
    "       This line just gets the name of the indicator we are working on.\n",
    "       indicator_name = \"Literacy rate\"\n",
    "\n",
    "    2. criteria = criteria_dict.get(indicator_name, 1)\n",
    "       This looks up the \"Literacy rate\" in our criteria dictionary and finds its requirement.\n",
    "       criteria = 2 (meaning we need at least 2 data points per 5-year window)\n",
    "\n",
    "    3. binned_years = pd.cut(...)\n",
    "       This is the categorization step. It takes our list of years and puts each one into a 5-year \"bucket\".\n",
    "       2011 -> [2010, 2015), 2012 -> [2010, 2015)\n",
    "       2016 -> [2015, 2020), 2018 -> [2015, 2020)\n",
    "       2021 -> [2020, 2025), 2022 -> [2020, 2025), 2023 -> [2020, 2025)\n",
    "\n",
    "    4. window_counts = binned_years.value_counts()\n",
    "       This step counts how many data points landed in each bucket.\n",
    "       [2010, 2015): 2\n",
    "       [2015, 2020): 2\n",
    "       [2020, 2025): 3\n",
    "\n",
    "    5. windows_with_sufficient_data = window_counts[window_counts >= criteria]\n",
    "       This is a filter. It keeps only buckets where the count meets our criteria (>= 2).\n",
    "       [2010, 2015): Kept (because 2 >= 2)\n",
    "       [2015, 2020): Kept (because 2 >= 2)\n",
    "       [2020, 2025): Kept (because 3 >= 2)\n",
    "\n",
    "    6. sufficient_windows_set = set(windows_with_sufficient_data.index)\n",
    "       This creates a clean, unique list of the windows that passed the filter.\n",
    "       sufficient_windows_set = { [2010, 2015), [2015, 2020), [2020, 2025) }\n",
    "\n",
    "    7. return 1 if len(...) == len(...) else 0\n",
    "       The final check compares the set of windows with sufficient data against the set of ALL possible windows in our universal time range.\n",
    "       If they match perfectly, it means the indicator is fully available (returns 1), otherwise it's not (returns 0).\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69ba9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read successfully.\n",
      "Cleaning source data...\n",
      "Creating year bins with hardcoded ranges...\n",
      "Data cleaning and binning complete.\n"
     ]
    }
   ],
   "source": [
    "#LOAD AND CLEAN DATA ---\n",
    "\n",
    "try:\n",
    "    main_df = pd.read_excel(MAIN_DATA_FILE)\n",
    "    criteria_df = pd.read_excel(CRITERIA_FILE)\n",
    "    print(\"Files read successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading files: {e}. Make sure the paths are correct.\")\n",
    "    raise e\n",
    "\n",
    "print(\"Cleaning source data...\")\n",
    "main_df = main_df.loc[:, ~main_df.columns.str.startswith('Unnamed')]\n",
    "if 'Theme' in main_df.columns:\n",
    "    main_df.rename(columns={'Theme': 'الفصل'}, inplace=True)\n",
    "for col in main_df.select_dtypes(include=['object']).columns:\n",
    "    main_df[col] = main_df[col].str.strip()\n",
    "\n",
    "# Keep only rows with a non-null value before doing anything else\n",
    "main_df.dropna(subset=['المؤشر'], inplace=True)\n",
    "main_df = main_df[main_df['العدد'].notna()].copy()\n",
    "\n",
    "# --- NEW BINNING LOGIC ---\n",
    "def assign_bin_hardcoded(year):\n",
    "    \"\"\"Manually assigns a year to a specific, hardcoded bin.\"\"\"\n",
    "    if 2010 <= year < 2015:\n",
    "        return '[2010-2015)'\n",
    "    elif 2015 <= year < 2020:\n",
    "        return '[2015-2020)'\n",
    "    elif 2020 <= year <= 2025:  # NOTE: Includes 2025 as requested\n",
    "        return '[2020-2025]'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "print(\"Creating year bins with hardcoded ranges...\")\n",
    "main_df['year_bins'] = main_df['السنة'].apply(assign_bin_hardcoded)\n",
    "main_df.dropna(subset=['year_bins'], inplace=True) # Remove rows outside the defined bins\n",
    "\n",
    "print(\"Data cleaning and binning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c26be734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria dictionary created with 85 entries.\n"
     ]
    }
   ],
   "source": [
    "#PREPARE FOR CALCULATION\n",
    "\n",
    "criteria_dict_ar = create_criteria_dict(criteria_df, key_language='arabic')\n",
    "print(f\"Criteria dictionary created with {len(criteria_dict_ar)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37de443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Availability Scores ---\n",
      "Availability scores calculated successfully.\n"
     ]
    }
   ],
   "source": [
    "# %% --- CELL 5: CALCULATE AVAILABILITY SCORES (CORRECTED LOGIC) ---\n",
    "\n",
    "print(\"\\n--- Calculating Availability Scores ---\")\n",
    "\n",
    "# The correct rule: Availability = 1 ONLY IF the indicator has data in all 3 defined time bins.\n",
    "\n",
    "# --- General Availability ---\n",
    "# Group by indicator/country and count the number of unique bins for each.\n",
    "general_bin_counts = main_df.groupby(['المؤشر', 'الدولة'])['year_bins'].nunique()\n",
    "# The final score is 1 only if the count of bins is exactly 3.\n",
    "final_general_scores = (general_bin_counts == 3).astype(int)\n",
    "\n",
    "# --- Nationality Availability ---\n",
    "df_nationality = main_df[main_df['المواطنة'].isin(['مواطنون', 'غير مواطنين'])]\n",
    "nat_bin_counts = df_nationality.groupby(['المؤشر', 'الدولة'])['year_bins'].nunique()\n",
    "# The final score is 1 only if the count of bins is exactly 3.\n",
    "final_nationality_scores = (nat_bin_counts == 3).astype(int)\n",
    "\n",
    "# --- Area Availability ---\n",
    "if 'المنطقة' in main_df.columns:\n",
    "    df_area = main_df[main_df['المنطقة'].isin(['حضر', 'ريف'])]\n",
    "    area_bin_counts = df_area.groupby(['المؤشر', 'الدولة'])['year_bins'].nunique()\n",
    "    # The final score is 1 only if the count of bins is exactly 3.\n",
    "    final_area_scores = (area_bin_counts == 3).astype(int)\n",
    "else:\n",
    "    final_area_scores = pd.Series(dtype=int)\n",
    "\n",
    "# --- Combine the results ---\n",
    "indicator_country_scores = pd.DataFrame({\n",
    "    'التوفر كلي': final_general_scores,\n",
    "    'التوفر حسب المواطنية': final_nationality_scores,\n",
    "    'التوفر حسب المنطقة': final_area_scores\n",
    "}).reset_index().fillna(0)\n",
    "\n",
    "print(\"Availability scores calculated successfully.\")\n",
    "# You can now display `indicator_country_scores.head()` in a new cell to inspect the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Detailed Masterfile ---\n",
      "Found 253 unique categorical combinations for the grid.\n",
      "Created a complete grid with 4048 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_16696\\4096763376.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  source_data_with_scores[col].fillna('N/A', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 'masterfile_detailed_availability.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "#CREATE MASTERFILE\n",
    "\n",
    "print(\"\\n--- Creating Detailed Masterfile ---\")\n",
    "\n",
    "source_data_with_scores = pd.merge(main_df, indicator_country_scores, on=['المؤشر', 'الدولة'], how='left')\n",
    "\n",
    "categorical_cols = ['الفصل', 'المؤشر', 'الدولة', 'المواطنة', 'المنطقة']\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in source_data_with_scores.columns]\n",
    "\n",
    "# Fill NaNs with a placeholder string to make them mergeable\n",
    "for col in existing_categorical_cols:\n",
    "    if source_data_with_scores[col].dtype == 'object':\n",
    "        source_data_with_scores[col].fillna('N/A', inplace=True)\n",
    "\n",
    "# Create a grid of all unique combinations of categories\n",
    "unique_combinations = source_data_with_scores[existing_categorical_cols].drop_duplicates()\n",
    "print(f\"Found {len(unique_combinations)} unique categorical combinations for the grid.\")\n",
    "\n",
    "# Create a grid of all years\n",
    "data_max_year = main_df['السنة'].max()\n",
    "grid_max_year = max(data_max_year, 2025)\n",
    "all_years = pd.DataFrame({'السنة': range(2010, grid_max_year + 1)})\n",
    "\n",
    "# Combine categories and years to create the complete blank grid\n",
    "complete_grid = unique_combinations.merge(all_years, how='cross')\n",
    "print(f\"Created a complete grid with {len(complete_grid)} rows.\")\n",
    "\n",
    "# Merge the actual data onto the complete grid\n",
    "merge_keys = existing_categorical_cols + ['السنة']\n",
    "masterfile_df = pd.merge(complete_grid, source_data_with_scores, on=merge_keys, how='left')\n",
    "\n",
    "# Forward and back fill the availability scores to fill in the blank years\n",
    "availability_cols = ['التوفر كلي', 'التوفر حسب المواطنية', 'التوفر حسب المنطقة']\n",
    "availability_cols_exist = [col for col in availability_cols if col in masterfile_df.columns]\n",
    "\n",
    "if availability_cols_exist:\n",
    "    masterfile_df[availability_cols_exist] = masterfile_df.groupby(['المؤشر', 'الدولة'])[availability_cols_exist].ffill().bfill()\n",
    "    masterfile_df[availability_cols_exist] = masterfile_df[availability_cols_exist].fillna(0).astype(int)\n",
    "\n",
    "# Select and order the final columns\n",
    "final_master_cols = ['الفصل', 'المؤشر', 'الدولة', 'السنة', 'العدد', 'المواطنة', 'المنطقة', 'year_bins'] + availability_cols\n",
    "cols_to_keep = [col for col in final_master_cols if col in masterfile_df.columns]\n",
    "masterfile_df = masterfile_df[cols_to_keep]\n",
    "\n",
    "# Define the columns to check for duplicates (all final columns EXCEPT the value column 'العدد')\n",
    "duplicate_check_cols = [col for col in cols_to_keep if col != 'العدد']\n",
    "\n",
    "# Remove duplicate rows based on this subset, keeping the first unique row.\n",
    "masterfile_df.drop_duplicates(subset=duplicate_check_cols, keep='first', inplace=True)\n",
    "print(\"Duplicate rows (excluding the 'العدد' column) removed.\")\n",
    "\n",
    "# Save the masterfile\n",
    "masterfile_df.to_excel('masterfile_detailed_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'masterfile_detailed_availability.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32f129a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating and Saving All Aggregated Reports ---\n",
      "Successfully saved 'main_availability.xlsx'\n",
      "Successfully saved 'main_availability_percentage.xlsx'\n",
      "Successfully saved 'theme_country_availability.xlsx'\n",
      "Successfully saved 'indicator_country_availability.xlsx'\n",
      "Successfully saved 'country_availability.xlsx'\n",
      "Successfully saved 'heatmap_disaggregated.xlsx'\n",
      "Successfully saved 'heatmap_total.xlsx'\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "#GENERATE AGGREGATED REPORTS\n",
    "\n",
    "print(\"\\n--- Generating and Saving All Aggregated Reports ---\")\n",
    "availability_cols = ['التوفر كلي', 'التوفر حسب المواطنية', 'التوفر حسب المنطقة']\n",
    "\n",
    "# --- File 1: main_availability.xlsx ---\n",
    "# This file shows the final 0/1 availability for each indicator/country pair.\n",
    "main_availability_agg_df = masterfile_df.groupby(['المؤشر', 'الفصل', 'الدولة']).agg({\n",
    "    'التوفر كلي': 'max',\n",
    "    'التوفر حسب المواطنية': 'max',\n",
    "    'التوفر حسب المنطقة': 'max'\n",
    "}).reset_index()\n",
    "main_availability_agg_df.to_excel('main_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'main_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 2: main_availability_percentage.xlsx ---\n",
    "# This file shows the percentage of available indicators per theme and country.\n",
    "long_availability_df = main_availability_agg_df.melt(\n",
    "    id_vars=['المؤشر', 'الفصل', 'الدولة'],\n",
    "    value_vars=availability_cols,\n",
    "    var_name='نوع التوفر',\n",
    "    value_name='متوفر'\n",
    ")\n",
    "total_indicators = main_df['المؤشر'].nunique()\n",
    "availability_sums = long_availability_df.groupby(['الفصل', 'الدولة', 'نوع التوفر'])['متوفر'].apply(\n",
    "    lambda x: (x.sum() / total_indicators) * 100 if total_indicators > 0 else 0\n",
    ").reset_index(name='نسبة التوفر')\n",
    "availability_sums = availability_sums[availability_sums['نوع التوفر'] == 'التوفر كلي']\n",
    "availability_sums.to_excel('main_availability_percentage.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'main_availability_percentage.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 3: theme_country_availability.xlsx ---\n",
    "# This file shows the number and percentage of available indicators for each theme/country.\n",
    "indicators_per_theme = main_df.groupby('الفصل')['المؤشر'].nunique().reset_index(name='total_indicators_in_theme')\n",
    "theme_country_sums = main_availability_agg_df.groupby(['الفصل', 'الدولة'])[availability_cols].sum().reset_index()\n",
    "theme_country_agg_df = pd.merge(theme_country_sums, indicators_per_theme, on='الفصل', how='left')\n",
    "for col in availability_cols:\n",
    "    theme_country_agg_df[f'{col}_نسبة'] = (theme_country_agg_df[col] / theme_country_agg_df['total_indicators_in_theme']) * 100\n",
    "theme_country_agg_df.to_excel('theme_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'theme_country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 4: indicator_country_availability.xlsx ---\n",
    "# This file shows the number and percentage of countries that have data for each indicator.\n",
    "indicator_sums = main_availability_agg_df.groupby('المؤشر')[availability_cols].sum().reset_index()\n",
    "total_countries = main_df['الدولة'].nunique()\n",
    "if total_countries > 0:\n",
    "    for col in availability_cols:\n",
    "        indicator_sums[f'{col}_نسبة'] = (indicator_sums[col] / total_countries) * 100\n",
    "indicator_sums.to_excel('indicator_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'indicator_country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 5: country_availability.xlsx ---\n",
    "# This file shows the number and percentage of available indicators for each country.\n",
    "country_sums = main_availability_agg_df.groupby('الدولة')[availability_cols].sum().reset_index()\n",
    "if total_indicators > 0:\n",
    "    for col in availability_cols:\n",
    "        country_sums[f'{col}_نسبة'] = (country_sums[col] / total_indicators) * 100\n",
    "country_sums['التوفر السابق'] = ''\n",
    "country_sums.to_excel('country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 6 & 7: Heatmap Files ---\n",
    "# Disaggregated Heatmap\n",
    "heatmap_df_disaggregated = masterfile_df.groupby(\n",
    "    ['المؤشر', 'الدولة', 'السنة', 'المواطنة', 'المنطقة', 'الفصل']\n",
    ").agg({'التوفر كلي': 'max'}).reset_index()\n",
    "heatmap_df_disaggregated.to_excel('heatmap_disaggregated.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'heatmap_disaggregated.xlsx'\")\n",
    "\n",
    "# Total (Aggregated) Heatmap\n",
    "heatmap_df_total = masterfile_df.groupby(\n",
    "    ['المؤشر', 'الدولة', 'السنة', 'الفصل']\n",
    ").agg({'التوفر كلي': 'max'}).reset_index()\n",
    "heatmap_df_total.to_excel('heatmap_total.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'heatmap_total.xlsx'\")\n",
    "\n",
    "\n",
    "print(\"\\nAnalysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62e766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a67ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d18d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f02bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc37e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8f768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0377c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d4300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba7e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cd15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f040e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fa976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a083d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
