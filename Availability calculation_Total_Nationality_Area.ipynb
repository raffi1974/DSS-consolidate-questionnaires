{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8951d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set options to display all rows and columns without truncation.\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "MAIN_DATA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/arabic_questionnaires.xlsx'\n",
    "CRITERIA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/criterias.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ee798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_criteria_dict(criteria_df, key_language='arabic'):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping indicator names to their availability criteria.\n",
    "    \"\"\"\n",
    "    if key_language.lower() == 'english':\n",
    "        key_col = 'Indicator_En'\n",
    "    elif key_language.lower() == 'arabic':\n",
    "        key_col = 'Indicator_Ar'\n",
    "    else:\n",
    "        raise ValueError(\"key_language must be 'english' or 'arabic'\")\n",
    "    criteria_df.dropna(subset=[key_col], inplace=True)\n",
    "    return pd.Series(criteria_df.criteria.values, index=criteria_df[key_col]).to_dict()\n",
    "    \"\"\"\n",
    "    Calculates availability for each group, returning a collapsed Series (one result per group).\n",
    "    This function checks if data points for an indicator are present consistently across defined time windows.\n",
    "    \n",
    "    Example of the process for a single indicator group:\n",
    "    1. indicator_name = group.name[...]\n",
    "       This line just gets the name of the indicator we are working on.\n",
    "       indicator_name = \"Literacy rate\"\n",
    "\n",
    "    2. criteria = criteria_dict.get(indicator_name, 1)\n",
    "       This looks up the \"Literacy rate\" in our criteria dictionary and finds its requirement.\n",
    "       criteria = 2 (meaning we need at least 2 data points per 5-year window)\n",
    "\n",
    "    3. binned_years = pd.cut(...)\n",
    "       This is the categorization step. It takes our list of years and puts each one into a 5-year \"bucket\".\n",
    "       2011 -> [2010, 2015), 2012 -> [2010, 2015)\n",
    "       2016 -> [2015, 2020), 2018 -> [2015, 2020)\n",
    "       2021 -> [2020, 2025), 2022 -> [2020, 2025), 2023 -> [2020, 2025)\n",
    "\n",
    "    4. window_counts = binned_years.value_counts()\n",
    "       This step counts how many data points landed in each bucket.\n",
    "       [2010, 2015): 2\n",
    "       [2015, 2020): 2\n",
    "       [2020, 2025): 3\n",
    "\n",
    "    5. windows_with_sufficient_data = window_counts[window_counts >= criteria]\n",
    "       This is a filter. It keeps only buckets where the count meets our criteria (>= 2).\n",
    "       [2010, 2015): Kept (because 2 >= 2)\n",
    "       [2015, 2020): Kept (because 2 >= 2)\n",
    "       [2020, 2025): Kept (because 3 >= 2)\n",
    "\n",
    "    6. sufficient_windows_set = set(windows_with_sufficient_data.index)\n",
    "       This creates a clean, unique list of the windows that passed the filter.\n",
    "       sufficient_windows_set = { [2010, 2015), [2015, 2020), [2020, 2025) }\n",
    "\n",
    "    7. return 1 if len(...) == len(...) else 0\n",
    "       The final check compares the set of windows with sufficient data against the set of ALL possible windows in our universal time range.\n",
    "       If they match perfectly, it means the indicator is fully available (returns 1), otherwise it's not (returns 0).\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94e74b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read successfully.\n",
      "Creating year bins with hardcoded ranges...\n",
      "Data cleaning and binning complete.\n",
      "Criteria dictionary created with 85 entries.\n"
     ]
    }
   ],
   "source": [
    "#LOAD AND CLEAN DATA\n",
    "try:\n",
    "    main_df = pd.read_excel(MAIN_DATA_FILE)\n",
    "    criteria_df = pd.read_excel(CRITERIA_FILE)\n",
    "    print(\"Files read successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error reading files: {e}. Make sure the paths are correct.\")\n",
    "    raise e\n",
    "\n",
    "main_df.rename(columns={'Theme': 'الفصل'}, inplace=True)\n",
    "\n",
    "# Keep only rows with a non-null value before doing anything else\n",
    "main_df = main_df[main_df['العدد'].notna()].copy()\n",
    "\n",
    "# --- NEW BINNING LOGIC ---\n",
    "def assign_bin_hardcoded(year):\n",
    "    \"\"\"Manually assigns a year to a specific, hardcoded bin.\"\"\"\n",
    "    if 2010 <= year < 2015:\n",
    "        return '[2010-2015)'\n",
    "    elif 2015 <= year < 2020:\n",
    "        return '[2015-2020)'\n",
    "    elif 2020 <= year <= 2025:  # NOTE: Includes 2025 as requested\n",
    "        return '[2020-2025]'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "print(\"Creating year bins with hardcoded ranges...\")\n",
    "main_df['year_bins'] = main_df['السنة'].apply(assign_bin_hardcoded)\n",
    "print(\"Data cleaning and binning complete.\")\n",
    "    \n",
    "#get the criteria dictionary\n",
    "criteria_dict_ar = create_criteria_dict(criteria_df, key_language='arabic')\n",
    "print(f\"Criteria dictionary created with {len(criteria_dict_ar)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffb2738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_availability(group, criteria_dict):\n",
    "    \"\"\"Calculates availability for a single indicator/country group.\"\"\"\n",
    "    required_bins = {'[2010-2015)', '[2015-2020)', '[2020-2025]'}\n",
    "    if 'year_bins' not in group.columns or group.empty:\n",
    "        return 0\n",
    "    indicator_name = group['المؤشر'].iloc[0]\n",
    "    criteria = criteria_dict.get(indicator_name, 1)\n",
    "    bins_in_data = set(group['year_bins'].dropna().unique())\n",
    "    bins_are_complete = (bins_in_data == required_bins)\n",
    "    all_counts_are_sufficient = False\n",
    "    if bins_are_complete:\n",
    "        counts_per_bin = group['year_bins'].value_counts()\n",
    "        all_counts_are_sufficient = (counts_per_bin >= criteria).all()\n",
    "    if bins_are_complete and all_counts_are_sufficient:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d8ecd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\2462344378.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  overall_availability_scores = main_df.groupby(['المؤشر', 'الدولة']).apply(\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\2462344378.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  nationality_availability_scores = df_nat_filtered.groupby(['المؤشر', 'الدولة']).apply(\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\2462344378.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  area_availability_scores = df_area_filtered.groupby(['المؤشر', 'الدولة']).apply(\n"
     ]
    }
   ],
   "source": [
    "#  Calculate ALL Availability Scores\n",
    "#Prepare Filtered DataFrames for Disaggregations\n",
    "df_nat_filtered = main_df[main_df['المواطنة'].isin(['مواطنون', 'غير مواطنين'])]\n",
    "df_area_filtered = main_df[main_df['المنطقة'].isin(['حضر', 'ريف'])]\n",
    "#####################################################################################\n",
    "\n",
    "#Group-Level Availability Scores\n",
    "overall_availability_scores = main_df.groupby(['المؤشر', 'الدولة']).apply(\n",
    "    calculate_availability, criteria_dict=criteria_dict_ar\n",
    ").reset_index(name='التوفر الكلي')\n",
    "\n",
    "nationality_availability_scores = df_nat_filtered.groupby(['المؤشر', 'الدولة']).apply(\n",
    "    calculate_availability, criteria_dict=criteria_dict_ar\n",
    ").reset_index(name='التوفر حسب المواطنية')\n",
    "\n",
    "area_availability_scores = df_area_filtered.groupby(['المؤشر', 'الدولة']).apply(\n",
    "    calculate_availability, criteria_dict=criteria_dict_ar\n",
    "    ).reset_index(name='التوفر حسب المنطقة')\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "#Datapoint-Level Availability Scores\n",
    "datapoint_scores_general = main_df.groupby(['المؤشر', 'الدولة', 'السنة']).size().reset_index(name='توفر نقطة البيانات (كلي)')\n",
    "datapoint_scores_general['توفر نقطة البيانات (كلي)'] = 1\n",
    "\n",
    "datapoint_scores_nat = df_nat_filtered.groupby(['المؤشر', 'الدولة', 'السنة']).size().reset_index(name='توفر نقطة البيانات (المواطنة)')\n",
    "datapoint_scores_nat['توفر نقطة البيانات (المواطنة)'] = 1\n",
    "\n",
    "\n",
    "datapoint_scores_area = df_area_filtered.groupby(['المؤشر', 'الدولة', 'السنة']).size().reset_index(name='توفر نقطة البيانات (المنطقة)')\n",
    "datapoint_scores_area['توفر نقطة البيانات (المنطقة)'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46425d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating masterfile grid and merging all scores...\n"
     ]
    }
   ],
   "source": [
    "# Create a Proper Masterfile Grid (Corrected)\n",
    "print(\"Creating masterfile grid and merging all scores...\")\n",
    "\n",
    "# 1. Get the unique combinations of Theme, Indicator, and Country that ACTUALLY EXIST in your data.\n",
    "valid_combinations = main_df[['الفصل', 'المؤشر', 'الدولة']].drop_duplicates()\n",
    "print(f\"Found {len(valid_combinations)} valid combinations of Theme, Indicator, and Country.\")\n",
    "\n",
    "# 2. Get the full list of years.\n",
    "all_years = sorted(main_df['السنة'].unique())\n",
    "\n",
    "# 3. Create the masterfile grid by performing a 'cross' merge between the valid combinations and all years.\n",
    "# This is the correct way to build the grid without creating invalid rows.\n",
    "masterfile_df = pd.merge(valid_combinations, pd.DataFrame({'السنة': all_years}), how='cross')\n",
    "\n",
    "print(f\"Created a clean masterfile grid with {len(masterfile_df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6ad1fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  masterfile_df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  masterfile_df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  masterfile_df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  masterfile_df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  masterfile_df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  masterfile_df[col].fillna(0, inplace=True)\n",
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  masterfile_disaggregated.drop_duplicates(subset=grouping_keys, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 'masterfile_disaggregated.xlsx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_36012\\3641525005.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  masterfile.drop_duplicates(subset=grouping_keys, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 'masterfile.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Merge Everything into the Masterfile\n",
    "\n",
    "# Merge original data values first.\n",
    "masterfile_df = pd.merge(masterfile_df, main_df, on=['الفصل', 'المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "# Merge the group-level scores.\n",
    "masterfile_df = pd.merge(masterfile_df, overall_availability_scores, on=['المؤشر', 'الدولة'], how='left')\n",
    "masterfile_df = pd.merge(masterfile_df, nationality_availability_scores, on=['المؤشر', 'الدولة'], how='left')\n",
    "masterfile_df = pd.merge(masterfile_df, area_availability_scores, on=['المؤشر', 'الدولة'], how='left')\n",
    "\n",
    "# Merge the datapoint-level scores.\n",
    "masterfile_df = pd.merge(masterfile_df, datapoint_scores_general, on=['المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "masterfile_df = pd.merge(masterfile_df, datapoint_scores_nat, on=['المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "masterfile_df = pd.merge(masterfile_df, datapoint_scores_area, on=['المؤشر', 'الدولة', 'السنة'], how='left')\n",
    "\n",
    "# 1. Define all the score columns you want to clean.\n",
    "score_cols = [\n",
    "    'التوفر الكلي',\n",
    "    'التوفر حسب المواطنية',\n",
    "    'التوفر حسب المنطقة',\n",
    "    'توفر نقطة البيانات (كلي)',\n",
    "    'توفر نقطة البيانات (المواطنة)',\n",
    "    'توفر نقطة البيانات (المنطقة)'\n",
    "]\n",
    "\n",
    "# 2. Loop through the list and fill NaNs with 0 for each column found.\n",
    "for col in score_cols:\n",
    "    # Check if the column exists in the DataFrame to avoid errors\n",
    "    if col in masterfile_df.columns:\n",
    "        # .fillna(0, inplace=True) replaces all empty values in the column with 0\n",
    "        masterfile_df[col].fillna(0, inplace=True)\n",
    "        # Convert the column to integer type for clean data\n",
    "        masterfile_df[col] = masterfile_df[col].astype(int)\n",
    "\n",
    "\n",
    "#save the masterfile\n",
    "cols_to_keep=['الفصل', 'المؤشر', 'الدولة', 'السنة',  'المواطنة',\n",
    "       'العدد', 'المنطقة',  'التوفر الكلي',\n",
    "       'التوفر حسب المواطنية', 'التوفر حسب المنطقة',\n",
    "       'توفر نقطة البيانات (كلي)', 'توفر نقطة البيانات (المواطنة)',\n",
    "       'توفر نقطة البيانات (المنطقة)']\n",
    "grouping_keys = [\n",
    "    'الفصل', 'المؤشر', 'الدولة', 'السنة',\n",
    "    'المواطنة', 'المنطقة'\n",
    "]\n",
    "\n",
    "masterfile_disaggregated = masterfile_df[cols_to_keep]\n",
    "masterfile_disaggregated.drop_duplicates(subset=grouping_keys, inplace=True)\n",
    "\n",
    "masterfile_disaggregated.to_excel('masterfile_disaggregated.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'masterfile_disaggregated.xlsx'\")\n",
    "\n",
    "#save the masterfile\n",
    "cols_to_keep=['الفصل', 'المؤشر', 'الدولة', 'السنة',\n",
    "       'العدد', 'التوفر الكلي',\n",
    "       'التوفر حسب المواطنية', 'التوفر حسب المنطقة',\n",
    "       'توفر نقطة البيانات (كلي)', 'توفر نقطة البيانات (المواطنة)',\n",
    "       'توفر نقطة البيانات (المنطقة)']\n",
    "grouping_keys = [\n",
    "    'الفصل', 'المؤشر', 'الدولة', 'السنة'\n",
    "]\n",
    "\n",
    "masterfile = masterfile_df[cols_to_keep]\n",
    "masterfile.drop_duplicates(subset=grouping_keys, inplace=True)\n",
    "\n",
    "masterfile.to_excel('masterfile.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'masterfile.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98adafd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['الفصل', 'المؤشر', 'الدولة', 'السنة', 'المواطنة', 'العدد', 'المصدر',\n",
       "       'المنطقة', 'الجنس', 'الفئة العمرية', 'الحالة الزوجية',\n",
       "       'التصنيف الدولي لاسباب الوفاة', 'سبب الوفاة',\n",
       "       'أسباب البقاء خارج القوى العاملة', 'وضع العمالة',\n",
       "       'أقسام النشاط الإقتصادي', 'القطاع المؤسسي', 'أقسام المهن الرئيسية',\n",
       "       'نوع مكان الإقامة', 'نوع حيازة الوحدات السكنية', 'مصدر مياه الشرب',\n",
       "       'أنواع نظام التخلص من مياه الصرف الصحي', 'مصدر الإضاءة',\n",
       "       'المرحلة التعليمية', 'الفئة', 'نوع الخدمات/المنتجات', 'القطاع',\n",
       "       'year_bins', 'التوفر الكلي', 'التوفر حسب المواطنية',\n",
       "       'التوفر حسب المنطقة', 'توفر نقطة البيانات (كلي)',\n",
       "       'توفر نقطة البيانات (المواطنة)', 'توفر نقطة البيانات (المنطقة)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterfile_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32f129a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating and Saving All Aggregated Reports ---\n",
      "Successfully saved 'main_availability.xlsx'\n",
      "Successfully saved 'main_availability_percentage.xlsx'\n",
      "Successfully saved 'theme_country_availability.xlsx'\n",
      "Successfully saved 'indicator_country_availability.xlsx'\n",
      "Successfully saved 'country_availability.xlsx'\n"
     ]
    }
   ],
   "source": [
    "#GENERATE AGGREGATED REPORTS\n",
    "\n",
    "print(\"\\n--- Generating and Saving All Aggregated Reports ---\")\n",
    "availability_cols = ['التوفر الكلي', 'التوفر حسب المواطنية', 'التوفر حسب المنطقة']\n",
    "\n",
    "# --- File 1: main_availability.xlsx ---\n",
    "# This file shows the final 0/1 availability for each indicator/country pair.\n",
    "main_availability_agg_df = masterfile_df.groupby(['المؤشر', 'الفصل', 'الدولة']).agg({\n",
    "    'التوفر الكلي': 'max',\n",
    "    'التوفر حسب المواطنية': 'max',\n",
    "    'التوفر حسب المنطقة': 'max'\n",
    "}).reset_index()\n",
    "main_availability_agg_df.to_excel('main_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'main_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 2: main_availability_percentage.xlsx ---\n",
    "# This file shows the percentage of available indicators per theme and country.\n",
    "long_availability_df = main_availability_agg_df.melt(\n",
    "    id_vars=['المؤشر', 'الفصل', 'الدولة'],\n",
    "    value_vars=availability_cols,\n",
    "    var_name='نوع التوفر',\n",
    "    value_name='متوفر'\n",
    ")\n",
    "total_indicators = main_df['المؤشر'].nunique()\n",
    "availability_sums = long_availability_df.groupby(['الفصل', 'الدولة', 'نوع التوفر'])['متوفر'].apply(\n",
    "    lambda x: (x.sum() / total_indicators) * 100 if total_indicators > 0 else 0\n",
    ").reset_index(name='نسبة التوفر')\n",
    "availability_sums = availability_sums[availability_sums['نوع التوفر'] == 'التوفر كلي']\n",
    "availability_sums.to_excel('main_availability_percentage.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'main_availability_percentage.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 3: theme_country_availability.xlsx ---\n",
    "# This file shows the number and percentage of available indicators for each theme/country.\n",
    "indicators_per_theme = main_df.groupby('الفصل')['المؤشر'].nunique().reset_index(name='total_indicators_in_theme')\n",
    "theme_country_sums = main_availability_agg_df.groupby(['الفصل', 'الدولة'])[availability_cols].sum().reset_index()\n",
    "theme_country_agg_df = pd.merge(theme_country_sums, indicators_per_theme, on='الفصل', how='left')\n",
    "for col in availability_cols:\n",
    "    theme_country_agg_df[f'{col}_نسبة'] = (theme_country_agg_df[col] / theme_country_agg_df['total_indicators_in_theme']) * 100\n",
    "theme_country_agg_df.to_excel('theme_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'theme_country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 4: indicator_country_availability.xlsx ---\n",
    "# This file shows the number and percentage of countries that have data for each indicator.\n",
    "indicator_sums = main_availability_agg_df.groupby('المؤشر')[availability_cols].sum().reset_index()\n",
    "total_countries = main_df['الدولة'].nunique()\n",
    "if total_countries > 0:\n",
    "    for col in availability_cols:\n",
    "        indicator_sums[f'{col}_نسبة'] = (indicator_sums[col] / total_countries) * 100\n",
    "indicator_sums.to_excel('indicator_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'indicator_country_availability.xlsx'\")\n",
    "\n",
    "\n",
    "# --- File 5: country_availability.xlsx ---\n",
    "# This file shows the number and percentage of available indicators for each country.\n",
    "country_sums = main_availability_agg_df.groupby('الدولة')[availability_cols].sum().reset_index()\n",
    "if total_indicators > 0:\n",
    "    for col in availability_cols:\n",
    "        country_sums[f'{col}_نسبة'] = (country_sums[col] / total_indicators) * 100\n",
    "country_sums['التوفر السابق'] = ''\n",
    "country_sums.to_excel('country_availability.xlsx', index=False, engine='openpyxl')\n",
    "print(\"Successfully saved 'country_availability.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16ecee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['العمالة'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[main_df['المؤشر']=='نسبة العمالة إلى السكان']['الفصل'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad62e766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['الصحة', 'السكان', 'العمالة', 'السكن', 'التعليم', 'الفقر'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterfile[masterfile['المؤشر']=='نسبة العمالة إلى السكان']['الفصل'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a67ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d18d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f02bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc37e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8f768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0377c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d4300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba7e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cd15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f040e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fa976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a083d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
