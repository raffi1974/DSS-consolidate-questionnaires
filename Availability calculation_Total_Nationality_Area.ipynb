{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8951d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MAIN_DATA_FILE = 'C:/Users/511232/Desktop/DSS/MERGING GOOGLESHEETS QUESTIONNAIRES/codes/arabic_questionnaires.xlsx'\n",
    "CRITERIA_FILE = 'C:/Users/511232/Desktop/criterias.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_criteria_dict(criteria_df, key_language='arabic'):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping indicator names to their availability criteria.\n",
    "\n",
    "    Args:\n",
    "        criteria_df (pd.DataFrame): DataFrame containing indicator names and criteria.\n",
    "        key_language (str): 'english' or 'arabic'. Determines which indicator name to use as the key.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping indicator names to their integer criteria.\n",
    "    \"\"\"\n",
    "    if key_language.lower() == 'english':\n",
    "        key_col = 'Indicator_En'\n",
    "    elif key_language.lower() == 'arabic':\n",
    "        key_col = 'Indicator_Ar'\n",
    "    else:\n",
    "        raise ValueError(\"key_language must be 'english' or 'arabic'\")\n",
    "\n",
    "    # Drop rows where the key column is NaN to avoid issues\n",
    "    criteria_df.dropna(subset=[key_col], inplace=True)\n",
    "    \n",
    "    return pd.Series(criteria_df.criteria.values, index=criteria_df[key_col]).to_dict()\n",
    "\n",
    "\n",
    "def calculate_availability(df, group_cols, criteria_dict, global_max_year, year_col='السنة', indicator_col='المؤشر', window_size=5):\n",
    "    \"\"\"\n",
    "    Calculates availability for each group, returning a collapsed Series (one result per group).\n",
    "    This function checks if data points for an indicator are present consistently across defined time windows.\n",
    "    \n",
    "    Example of the process for a single indicator group:\n",
    "    1. indicator_name = group.name[...]\n",
    "       This line just gets the name of the indicator we are working on.\n",
    "       indicator_name = \"Literacy rate\"\n",
    "\n",
    "    2. criteria = criteria_dict.get(indicator_name, 1)\n",
    "       This looks up the \"Literacy rate\" in our criteria dictionary and finds its requirement.\n",
    "       criteria = 2 (meaning we need at least 2 data points per 5-year window)\n",
    "\n",
    "    3. binned_years = pd.cut(...)\n",
    "       This is the categorization step. It takes our list of years and puts each one into a 5-year \"bucket\".\n",
    "       2011 -> [2010, 2015), 2012 -> [2010, 2015)\n",
    "       2016 -> [2015, 2020), 2018 -> [2015, 2020)\n",
    "       2021 -> [2020, 2025), 2022 -> [2020, 2025), 2023 -> [2020, 2025)\n",
    "\n",
    "    4. window_counts = binned_years.value_counts()\n",
    "       This step counts how many data points landed in each bucket.\n",
    "       [2010, 2015): 2\n",
    "       [2015, 2020): 2\n",
    "       [2020, 2025): 3\n",
    "\n",
    "    5. windows_with_sufficient_data = window_counts[window_counts >= criteria]\n",
    "       This is a filter. It keeps only buckets where the count meets our criteria (>= 2).\n",
    "       [2010, 2015): Kept (because 2 >= 2)\n",
    "       [2015, 2020): Kept (because 2 >= 2)\n",
    "       [2020, 2025): Kept (because 3 >= 2)\n",
    "\n",
    "    6. sufficient_windows_set = set(windows_with_sufficient_data.index)\n",
    "       This creates a clean, unique list of the windows that passed the filter.\n",
    "       sufficient_windows_set = { [2010, 2015), [2015, 2020), [2020, 2025) }\n",
    "\n",
    "    7. return 1 if len(...) == len(...) else 0\n",
    "       The final check compares the set of windows with sufficient data against the set of ALL possible windows in our universal time range.\n",
    "       If they match perfectly, it means the indicator is fully available (returns 1), otherwise it's not (returns 0).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=int)\n",
    "\n",
    "    # Determine the overall year range and create standard bins using the global max year.\n",
    "    min_year = 2010\n",
    "    bins = range(min_year, global_max_year + window_size + 1, window_size)\n",
    "    \n",
    "    # Create a set of all possible windows (bins) that could exist based on the global range.\n",
    "    all_possible_windows = set(pd.cut(pd.Series(range(min_year, global_max_year + 1)), bins=bins, right=False).dropna().unique())\n",
    "    \n",
    "    results = {}\n",
    "    grouped = df.groupby(group_cols)\n",
    "    indicator_col_index = group_cols.index(indicator_col)\n",
    "\n",
    "    for name, group in grouped:\n",
    "        # 'name' is a tuple of the group keys, e.g., ('Indicator A', 'Country X')\n",
    "        indicator_name = name[indicator_col_index]\n",
    "        criteria = criteria_dict.get(indicator_name, 1)\n",
    "\n",
    "        binned_years = pd.cut(group[year_col], bins=bins, right=False)\n",
    "        window_counts = binned_years.value_counts()\n",
    "        \n",
    "        windows_with_sufficient_data = window_counts[window_counts >= criteria]\n",
    "        sufficient_windows_set = set(windows_with_sufficient_data.index)\n",
    "        \n",
    "        results[name] = 1 if len(sufficient_windows_set) == len(all_possible_windows) else 0\n",
    "\n",
    "    return pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4dd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read successfully.\n",
      "Cleaning source data...\n",
      "Data cleaning complete.\n",
      "Criteria dictionary created with 8 entries.\n",
      "Data maximum year is 2024. This will be used for availability calculation.\n",
      "\n",
      "--- Step 1: Calculating Availability Scores ---\n",
      "\n",
      "--- Step 2: Creating Detailed Masterfile ---\n",
      "Found 21 unique categorical combinations for the grid.\n",
      "Created a complete grid with 336 rows.\n",
      "Successfully saved 'masterfile_detailed_availability.xlsx'\n",
      "\n",
      "--- Step 3: Generating and Saving All Aggregated Reports ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\511232\\AppData\\Local\\Temp\\ipykernel_9272\\790160501.py:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  source_data_with_scores[col].fillna('N/A', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 'main_availability.xlsx'\n",
      "Successfully saved 'main_availability_percentage.xlsx'\n",
      "Successfully saved 'theme_country_availability.xlsx'\n",
      "Successfully saved 'indicator_country_availability.xlsx'\n",
      "Successfully saved 'country_availability.xlsx'\n",
      "Successfully saved 'heatmap.xlsx'\n",
      "Successfully saved 'heatmap_total.xlsx'\n",
      "\n",
      "--- Generating Theme-level Country Coverage Report ---\n",
      "Successfully saved 'themes.xlsx'\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire analysis pipeline.\n",
    "    \"\"\"\n",
    "    # 1. Read and Clean Data\n",
    "    try:\n",
    "        main_df = pd.read_excel(MAIN_DATA_FILE)\n",
    "        criteria_df = pd.read_excel(CRITERIA_FILE)\n",
    "        print(\"Files read successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error reading files: {e}. Make sure they are in the correct directory.\")\n",
    "        return\n",
    "\n",
    "    print(\"Cleaning source data...\")\n",
    "    main_df = main_df.loc[:, ~main_df.columns.str.startswith('Unnamed')]\n",
    "    if 'Theme' in main_df.columns:\n",
    "        main_df.rename(columns={'Theme': 'الفصل'}, inplace=True)\n",
    "    for col in main_df.select_dtypes(include=['object']).columns:\n",
    "        main_df[col] = main_df[col].str.strip()\n",
    "    print(\"Data cleaning complete.\")\n",
    "\n",
    "    # 2. Prepare for Calculations\n",
    "    criteria_dict_ar = create_criteria_dict(criteria_df, key_language='arabic')\n",
    "    print(f\"Criteria dictionary created with {len(criteria_dict_ar)} entries.\")\n",
    "    data_max_year = main_df['السنة'].max()\n",
    "    print(f\"Data maximum year is {data_max_year}. This will be used for availability calculation.\")\n",
    "\n",
    "    # 3. Calculate Availability Scores\n",
    "    print(\"\\n--- Step 1: Calculating Availability Scores ---\")\n",
    "    general_availability = calculate_availability(\n",
    "        main_df[main_df['العدد'].notna()], ['المؤشر', 'الدولة'], criteria_dict_ar, data_max_year)\n",
    "    nationality_availability = calculate_availability(\n",
    "        main_df[main_df['العدد'].notna() & main_df['المواطنة'].notna() & ~main_df['المواطنة'].isin(['Not applicable', 'غير مطابق', 'Total'])],\n",
    "        ['المؤشر', 'الدولة'], criteria_dict_ar, data_max_year)\n",
    "    if 'المنطقة' in main_df.columns:\n",
    "        area_availability = calculate_availability(\n",
    "            main_df[main_df['العدد'].notna() & main_df['المنطقة'].notna() & ~main_df['المنطقة'].isin(['Not applicable', 'غير مطابق', 'Total'])],\n",
    "            ['المؤشر', 'الدولة'], criteria_dict_ar, data_max_year)\n",
    "    else:\n",
    "        area_availability = pd.Series(dtype=int)\n",
    "\n",
    "    indicator_country_scores = pd.DataFrame({\n",
    "        'توفر كلي': general_availability,\n",
    "        'توفر حسب المواطنية': nationality_availability,\n",
    "        'توفر حسب المنطقة': area_availability\n",
    "    }).reset_index()\n",
    "    indicator_country_scores.rename(columns={'level_0': 'المؤشر', 'level_1': 'الدولة'}, inplace=True)\n",
    "    indicator_country_scores.fillna(0, inplace=True)\n",
    "    \n",
    "    # --- Step 4: Create Masterfile (New Simplified Approach) ---\n",
    "    print(\"\\n--- Step 2: Creating Detailed Masterfile ---\")\n",
    "    \"\"\" \n",
    "    This section builds a complete grid for every combination of categories and years.\n",
    "    This is essential for visualizations that need a value for every cell.\n",
    "    \"\"\"\n",
    "    # Step A: Prepare a single data source with original data and calculated scores.\n",
    "    # This includes the critical step of filling NaN in categorical columns to ensure merges work.\n",
    "    source_data_with_scores = pd.merge(main_df, indicator_country_scores, on=['المؤشر', 'الدولة'], how='left')\n",
    "    \n",
    "    categorical_cols = ['الفصل', 'المؤشر', 'الدولة', 'المواطنة', 'المنطقة']\n",
    "    existing_categorical_cols = [col for col in categorical_cols if col in source_data_with_scores.columns]\n",
    "    \n",
    "    # Fill NaNs with a placeholder string to make them mergeable\n",
    "    for col in existing_categorical_cols:\n",
    "        if source_data_with_scores[col].dtype == 'object':\n",
    "            source_data_with_scores[col].fillna('N/A', inplace=True)\n",
    "\n",
    "    # Step B: Create the \"blank\" master grid with all combinations and all years.\n",
    "    unique_combinations = source_data_with_scores[existing_categorical_cols].drop_duplicates()\n",
    "    print(f\"Found {len(unique_combinations)} unique categorical combinations for the grid.\")\n",
    "\n",
    "    grid_max_year = max(data_max_year, 2025)\n",
    "    all_years = pd.DataFrame({'السنة': range(2010, grid_max_year + 1)})\n",
    "    \n",
    "    complete_grid = unique_combinations.merge(all_years, how='cross')\n",
    "    print(f\"Created a complete grid with {len(complete_grid)} rows.\")\n",
    "\n",
    "    # Step C: Merge the prepared data onto the blank grid.\n",
    "    merge_keys = existing_categorical_cols + ['السنة']\n",
    "    masterfile_df = pd.merge(complete_grid, source_data_with_scores, on=merge_keys, how='left')\n",
    "    \n",
    "    availability_cols = ['توفر كلي', 'توفر حسب المواطنية', 'توفر حسب المنطقة']\n",
    "    availability_cols_exist = [col for col in availability_cols if col in masterfile_df.columns]\n",
    "    \n",
    "    if availability_cols_exist:\n",
    "        masterfile_df[availability_cols_exist] = masterfile_df.groupby(['المؤشر', 'الدولة'])[availability_cols_exist].ffill().bfill()\n",
    "        masterfile_df[availability_cols_exist] = masterfile_df[availability_cols_exist].fillna(0).astype(int)\n",
    "\n",
    "    final_master_cols = ['الفصل', 'المؤشر', 'الدولة', 'السنة', 'العدد', 'المواطنة', 'المنطقة'] + availability_cols\n",
    "    cols_to_keep = [col for col in final_master_cols if col in masterfile_df.columns]\n",
    "    masterfile_df = masterfile_df[cols_to_keep]\n",
    "\n",
    "    masterfile_df.to_excel('masterfile_detailed_availability.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'masterfile_detailed_availability.xlsx'\")\n",
    "\n",
    "    # --- Step 5: Generate and Save All Aggregated Reports ---\n",
    "    print(\"\\n--- Step 3: Generating and Saving All Aggregated Reports ---\")\n",
    "\n",
    "    # File 1: main_availability.xlsx\n",
    "    main_availability_agg_df = masterfile_df.groupby(['المؤشر', 'الفصل', 'الدولة']).agg({\n",
    "        'توفر كلي': 'max',\n",
    "        'توفر حسب المواطنية': 'max',\n",
    "        'توفر حسب المنطقة': 'max'\n",
    "    }).reset_index()\n",
    "    main_availability_agg_df.to_excel('main_availability.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'main_availability.xlsx'\")\n",
    "\n",
    "    # Create a long-format DataFrame from the aggregated availability data\n",
    "    long_availability_df = main_availability_agg_df.melt(\n",
    "        id_vars=['المؤشر', 'الفصل', 'الدولة'],\n",
    "        value_vars=['توفر كلي', 'توفر حسب المواطنية', 'توفر حسب المنطقة'],\n",
    "        var_name='نوع التوفر',\n",
    "        value_name='متوفر'\n",
    "    )\n",
    "    \n",
    "    # Create a long-format DataFrame from the aggregated availability data\n",
    "    long_availability_df = main_availability_agg_df.melt(\n",
    "        id_vars=['المؤشر', 'الفصل', 'الدولة'],\n",
    "        value_vars=['توفر كلي', 'توفر حسب المواطنية', 'توفر حسب المنطقة'],\n",
    "        var_name='نوع التوفر',\n",
    "        value_name='متوفر'\n",
    "    )\n",
    "    \n",
    "    # Get the total number of unique indicators in the entire dataset to use as the denominator\n",
    "    total_indicators = main_df['المؤشر'].nunique()\n",
    "\n",
    "    # Group by theme, country, and availability type, then use a lambda function with apply\n",
    "    # to calculate the percentage of available indicators over the total count in a single step.\n",
    "    availability_sums = long_availability_df.groupby(['الفصل', 'الدولة', 'نوع التوفر'])['متوفر'].apply(\n",
    "        lambda x: (x.sum() / total_indicators) * 100 if total_indicators > 0 else 0\n",
    "    ).reset_index(name='نسبة التوفر')\n",
    "\n",
    "    # Filter to keep only the 'توفر كلي' (Total Availability) type as requested\n",
    "    availability_sums = availability_sums[availability_sums['نوع التوفر'] == 'توفر كلي']\n",
    "\n",
    "    # Save the new aggregated file\n",
    "    availability_sums.to_excel('main_availability_percentage.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'main_availability_percentage.xlsx'\")\n",
    "\n",
    "\n",
    "    # File 2: theme_country_availability.xlsx\n",
    "    indicators_per_theme = main_df.groupby('الفصل')['المؤشر'].nunique().reset_index().rename(columns={'المؤشر': 'total_indicators_in_theme'})\n",
    "    theme_country_sums = main_availability_agg_df.groupby(['الفصل', 'الدولة'])[availability_cols].sum().reset_index()\n",
    "    theme_country_agg_df = pd.merge(theme_country_sums, indicators_per_theme, on='الفصل', how='left')\n",
    "    for col in availability_cols:\n",
    "        theme_country_agg_df[col + '_نسبة'] = (theme_country_agg_df[col] / theme_country_agg_df['total_indicators_in_theme']) * 100\n",
    "    theme_country_agg_df.to_excel('theme_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'theme_country_availability.xlsx'\")\n",
    "\n",
    "    # File 3: indicator_country_availability.xlsx\n",
    "    indicator_country_agg_df = main_availability_agg_df.groupby(['المؤشر', 'الدولة'])[availability_cols].max().reset_index()\n",
    "    # Create a separate dataframe for the percentage calculation to be saved.\n",
    "    # Sum the availabilities for each indicator to count how many countries have it.\n",
    "    indicator_sums = indicator_country_agg_df.groupby('المؤشر')[availability_cols].sum().reset_index()\n",
    "    \n",
    "    # Get the total number of unique countries in the dataset\n",
    "    total_countries = main_df['الدولة'].nunique()\n",
    "    \n",
    "    # Calculate the percentage over the total number of countries\n",
    "    if total_countries > 0:\n",
    "        for col in availability_cols:\n",
    "            indicator_sums[col + '_نسبة'] = (indicator_sums[col] / total_countries) * 100\n",
    "            \n",
    "    indicator_sums.to_excel('indicator_country_availability.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'indicator_country_availability.xlsx'\")\n",
    "    \n",
    "    # File 4: country_availability.xlsx\n",
    "    total_indicators = main_df['المؤشر'].nunique()\n",
    "    country_sums = indicator_country_agg_df.groupby('الدولة')[availability_cols].sum().reset_index()\n",
    "    if total_indicators > 0:\n",
    "        for col in availability_cols:\n",
    "            country_sums[col + '_نسبة'] = (country_sums[col] / total_indicators) * 100\n",
    "    country_sums.to_excel('country_availability.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'country_availability.xlsx'\")\n",
    "\n",
    "    # File 5: heatmap_disaggregated.xlsx\n",
    "    heatmap_agg_dict = {\n",
    "        'توفر كلي': 'max',\n",
    "        'توفر حسب المواطنية': 'max',\n",
    "        'توفر حسب المنطقة': 'max',\n",
    "        'الفصل': 'first'\n",
    "    }\n",
    "    heatmap_group_cols = ['المؤشر', 'الدولة', 'السنة', 'المواطنة', 'المنطقة']\n",
    "    existing_heatmap_cols = [col for col in heatmap_group_cols if col in masterfile_df.columns]\n",
    "    heatmap_df = masterfile_df.groupby(existing_heatmap_cols).agg(heatmap_agg_dict).reset_index()\n",
    "    heatmap_df.to_excel('heatmap_disaggregated.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'heatmap.xlsx'\")\n",
    "\n",
    "    # File 6: heatmap_total.xlsx\n",
    "    heatmap_agg_dict = {\n",
    "        'توفر كلي': 'max',\n",
    "        'توفر حسب المواطنية': 'max',\n",
    "        'توفر حسب المنطقة': 'max',\n",
    "        'الفصل': 'first'\n",
    "    }\n",
    "    heatmap_group_cols = ['المؤشر', 'الدولة', 'السنة']\n",
    "    existing_heatmap_cols = [col for col in heatmap_group_cols if col in masterfile_df.columns]\n",
    "    heatmap_df = masterfile_df.groupby(existing_heatmap_cols).agg(heatmap_agg_dict).reset_index()\n",
    "    heatmap_df.to_excel('heatmap_total.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'heatmap_total.xlsx'\")\n",
    "    \n",
    "    # File 7: themes.xlsx\n",
    "    print(\"\\n--- Generating Theme-level Country Coverage Report ---\")\n",
    "    \n",
    "    # Use the main_availability_agg_df which has 0/1 for availability per indicator/theme/country\n",
    "    # First, determine if a country has ANY available indicator for a given theme by taking the max\n",
    "    theme_country_any_avail = main_availability_agg_df.groupby(['الفصل', 'الدولة'])[availability_cols].max().reset_index()\n",
    "    \n",
    "    # Now, sum these 0/1 flags. The sum represents the count of countries that have data for each theme.\n",
    "    theme_sums = theme_country_any_avail.groupby('الفصل')[availability_cols].sum().reset_index()\n",
    "    \n",
    "    # Get the total number of unique countries in the entire dataset to use as the denominator\n",
    "    total_countries = main_df['الدولة'].nunique()\n",
    "    \n",
    "    # Calculate the percentage over the total number of countries\n",
    "    if total_countries > 0:\n",
    "        for col in availability_cols:\n",
    "            theme_sums[col + '_نسبة'] = (theme_sums[col] / total_countries) * 100\n",
    "            \n",
    "    theme_sums.to_excel('themes.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"Successfully saved 'themes.xlsx'\")\n",
    "    # --- END OF CHANGE ---\n",
    "\n",
    "    print(\"\\nAnalysis complete.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad1813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62e766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a67ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d18d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f02bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc37e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8f768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0377c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d4300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba7e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cd15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f040e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fa976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a083d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
